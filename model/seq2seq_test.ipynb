{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Import Package_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global device\n",
    "global vocab_size\n",
    "global bert_model_hidden_size\n",
    "global lstm_hidden_size\n",
    "global num_layers\n",
    "global batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# global variable iinitialize\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# print(torch.cuda.get_device_name())\n",
    "\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name).to(device)\n",
    "\n",
    "vocab_size = bert_model.config.vocab_size\n",
    "bert_model_hidden_size = bert_model.config.hidden_size\n",
    "lstm_hidden_size = 256\n",
    "num_layers = 4\n",
    "batch_size = 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Encoder_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, bert_model):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # with torch.no_grad():\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        return last_hidden_state\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Decoder_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, lstm_hidden_size, num_layers, vocab_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=bert_model.config.hidden_size,\n",
    "                            hidden_size=lstm_hidden_size,\n",
    "                            num_layers=num_layers).to(device)\n",
    "        self.linear1 = nn.Linear(lstm_hidden_size, lstm_hidden_size * 2).to(device)\n",
    "        self.linear2 = nn.Linear(lstm_hidden_size * 2, lstm_hidden_size * 4).to(device)\n",
    "        self.linear3 = nn.Linear(lstm_hidden_size * 4, vocab_size).to(device)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        lstm_outputs, _ = self.lstm(input)\n",
    "        output = self.linear1(lstm_outputs)\n",
    "        output = self.linear2(output)\n",
    "        prediction = self.linear3(output)\n",
    "        return prediction\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Seq2Seq_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder) -> None:\n",
    "        '''\n",
    "        '''\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        last_hidden_state = self.encoder(input_ids, attention_mask)\n",
    "        decoder_output = self.decoder(last_hidden_state)\n",
    "        return decoder_output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seqwithattn(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, attn_embed_dim, num_heads) -> None:\n",
    "        super(Seq2Seqwithattn, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.multihead_attn = nn.MultiheadAttention(attn_embed_dim, num_heads).to(device)\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, target_ids):\n",
    "        encoder_outputs  = self.encoder(input_ids, attention_mask)\n",
    "        target_outputs = self.encoder(target_ids, attention_mask)\n",
    "        attn_output, _ = self.multihead_attn(target_outputs,\n",
    "                                             encoder_outputs,\n",
    "                                             encoder_outputs)\n",
    "        decoder_outputs = self.decoder(attn_output)\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bertsformer(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, bert_model_hidden_size) -> None:\n",
    "        super(bertsformer, self).__init__()\n",
    "        self.bert_encoder = encoder\n",
    "        self.decoder_layer  = nn.TransformerDecoderLayer(d_model=bert_model_hidden_size, nhead=8).to(device)\n",
    "        self.trans_decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=6, norm=nn.LayerNorm(bert_model_hidden_size)).to(device)\n",
    "        self.output_layer = nn.Linear(bert_model_hidden_size, vocab_size).to(device)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, target_ids):\n",
    "        input_hidden_state = self.bert_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        target_hidden_state = self.bert_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        trans_decoder_output = self.trans_decoder(target_hidden_state, input_hidden_state)\n",
    "        output = self.output_layer(trans_decoder_output)\n",
    "        return output\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Preprocess data_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(text):\n",
    "    return [tok.text for tok in nlp.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PubMedDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, tokenizer) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_seq = self.df.loc[index, \"input\"]\n",
    "        target_seq = self.df.loc[index, \"target\"]\n",
    "\n",
    "        encoded_inputs = self.tokenizer.encode_plus(\n",
    "            input_seq,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length', \n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        encoded_targets = self.tokenizer.encode_plus(\n",
    "            target_seq,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = encoded_inputs['input_ids'].squeeze(0)\n",
    "        attention_mask = encoded_inputs['attention_mask'].squeeze(0)\n",
    "        target_ids = encoded_targets['input_ids'].squeeze(0)\n",
    "\n",
    "        return input_ids, attention_mask, target_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "training_set = r'./../spider/meddialog/results/eval_wer_json/pubmed_46374_train.json'\n",
    "with open(training_set, 'r') as td:\n",
    "    data = json.load(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46374\n",
      "                                               input   \n",
      "0  This study aimed to investigate the efficacy a...  \\\n",
      "1  Over recent decades , the abundance and geogra...   \n",
      "2  There are few data on the prevalence of obesit...   \n",
      "3  Cytomegalovirus establishes a lifelong infecti...   \n",
      "4  Early identification of patients with acute di...   \n",
      "\n",
      "                                              target  \n",
      "0  this study aimed toinvestigate the efficacy an...  \n",
      "1  over recent decades the abundance and geograph...  \n",
      "2  there are few data and the prevalence of obesi...  \n",
      "3  cytomegalovirus establishes lifelong infection...  \n",
      "4  early identification and patients with acute d...  \n"
     ]
    }
   ],
   "source": [
    "utterances = []\n",
    "results = []\n",
    "\n",
    "for d in data:\n",
    "    utterances.append(d['utterances']['pubmed'])\n",
    "    results.append(d['results']['pubmed'][2:])\n",
    "\n",
    "print(len(utterances))\n",
    "\n",
    "pubmed_df = pd.DataFrame({'input': utterances, 'target': results})\n",
    "PD = PubMedDataset(pubmed_df, bert_tokenizer)\n",
    "dataloader = DataLoader(PD, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(pubmed_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Train model_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloader, num_epochs, clip):\n",
    "    \n",
    "    # batch accumulation parameter\n",
    "    accum_iter = 32\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (input_ids, attention_mask, target_ids) in tqdm(enumerate(dataloader), desc=f'Epoch {epoch + 1}', ncols=30):\n",
    "            # optimizer.zero_grad()\n",
    "\n",
    "            # 將資料移到 device\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            target_ids = target_ids.to(device)\n",
    "            \n",
    "            # passes and weights update\n",
    "            with torch.set_grad_enabled(True):\n",
    "                \n",
    "                # forward\n",
    "                outputs = model(input_ids, attention_mask, target_ids)\n",
    "                loss = criterion(outputs.view(-1, vocab_size), target_ids.view(-1))\n",
    "\n",
    "                # normalize loss to account for batch accumulation\n",
    "                loss = loss / accum_iter\n",
    "\n",
    "                # backward & optimization\n",
    "                loss.backward()\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "                if ((batch_idx + 1) % accum_iter == 0) or (batch_idx + 1 == len(dataloader)):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # loss = criterion(outputs.view(-1, vocab_size), target_ids.view(-1))\n",
    "                    # if ((batch_idx + 1) % 1000 == 0):\n",
    "                        # print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(dataloader)}], Loss: {loss.item()}\")\n",
    "        loss = criterion(outputs.view(-1, vocab_size), target_ids.view(-1))\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 4it [00:28,  7.06s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdamW(seq2seq_with_attn_model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.00008\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39m# optimizer = torch.optim.AdamW(bertsformer.parameters(), lr=0.00001)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m train_model(seq2seq_with_attn_model, \\\n\u001b[0;32m     18\u001b[0m             criterion\u001b[39m=\u001b[39;49mcriterion, \\\n\u001b[0;32m     19\u001b[0m             optimizer\u001b[39m=\u001b[39;49moptimizer, \\\n\u001b[0;32m     20\u001b[0m             dataloader\u001b[39m=\u001b[39;49mdataloader, \\\n\u001b[0;32m     21\u001b[0m             num_epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,\n\u001b[0;32m     22\u001b[0m             clip\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     24\u001b[0m \u001b[39m# torch.save(model.state_dict(), 'model.pth')\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 28\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, dataloader, num_epochs, clip)\u001b[0m\n\u001b[0;32m     25\u001b[0m loss \u001b[39m=\u001b[39m loss \u001b[39m/\u001b[39m accum_iter\n\u001b[0;32m     27\u001b[0m \u001b[39m# backward & optimization\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     30\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), clip)\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m ((batch_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m accum_iter \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m (batch_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(dataloader)):\n",
      "File \u001b[1;32mc:\\Users\\EricHsu\\Desktop\\code\\spider\\.venv\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\EricHsu\\Desktop\\code\\spider\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder = Encoder(bert_model=bert_model)\n",
    "decoder = Decoder(lstm_hidden_size=lstm_hidden_size, num_layers=num_layers, vocab_size=vocab_size)\n",
    "# bert_lstm_s2s_model = Seq2Seq(encoder, decoder)\n",
    "seq2seq_with_attn_model = Seq2Seqwithattn(encoder, decoder, bert_model.config.hidden_size, 8)\n",
    "# bertsformer = bertsformer(encoder, bert_model_hidden_size=bert_model_hidden_size)\n",
    "\n",
    "# SRC_PAD_IDX = bert_tokenizer.pad_token_id\n",
    "# TRG_PAD_IDX = bert_tokenizer.pad_token_id\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(bert_lstm_s2s_model.parameters(), lr=0.001)\n",
    "# optimizer = torch.optim.AdamW(bert_lstm_s2s_model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.AdamW(seq2seq_with_attn_model.parameters(), lr=0.00008)\n",
    "# optimizer = torch.optim.AdamW(bertsformer.parameters(), lr=0.00001)\n",
    "\n",
    "train_model(seq2seq_with_attn_model, \\\n",
    "            criterion=criterion, \\\n",
    "            optimizer=optimizer, \\\n",
    "            dataloader=dataloader, \\\n",
    "            num_epochs=15,\n",
    "            clip=1)\n",
    "\n",
    "# torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Evaluate the model_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentences = []\n",
    "bert_lstm_s2s_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, target_ids in dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "        outputs = bert_lstm_s2s_model(input_ids, attention_mask)\n",
    "\n",
    "        _, predicted_ids = torch.max(outputs, dim=2)\n",
    "\n",
    "        for ids in predicted_ids:\n",
    "            tokens = bert_tokenizer.convert_ids_to_tokens(ids, skip_special_tokens=True)\n",
    "            sentence = bert_tokenizer.convert_tokens_to_string(tokens)\n",
    "            predicted_sentences.append(sentence)\n",
    "\n",
    "\n",
    "print(predicted_sentences[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTxt = 'Hello, World'\n",
    "\n",
    "encoded_inputs = bert_tokenizer.encode_plus(\n",
    "    testTxt,\n",
    "    add_special_tokens=True,\n",
    "    padding='max_length',\n",
    "    max_length=128,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.3778, -1.2009, -2.0004],\n",
      "          [ 1.4171,  0.4454,  1.2879],\n",
      "          [ 0.5370, -0.5584,  0.1352]],\n",
      "\n",
      "         [[ 0.3975,  0.0664,  1.0255],\n",
      "          [ 0.1967,  0.7439,  2.9432],\n",
      "          [-0.9861, -1.2516, -0.3943]],\n",
      "\n",
      "         [[-0.3417,  0.4060, -0.9845],\n",
      "          [-0.3367,  0.1158, -2.1325],\n",
      "          [-0.7750, -1.3084,  0.6354]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3053,  0.9232, -1.0590],\n",
      "          [-0.6940,  1.4665,  0.8403],\n",
      "          [ 0.9252, -0.3428,  0.3314]],\n",
      "\n",
      "         [[-0.4104,  0.1264,  0.2063],\n",
      "          [ 3.0852,  0.3418,  0.4495],\n",
      "          [ 0.8446,  0.2561, -0.7031]],\n",
      "\n",
      "         [[ 0.6151,  0.8057,  0.2074],\n",
      "          [-1.7569,  0.4648, -0.1453],\n",
      "          [ 0.8271,  0.8471, -1.1014]]],\n",
      "\n",
      "\n",
      "        [[[-0.2911, -0.9113,  2.4088],\n",
      "          [ 1.5399, -0.0792, -1.0721],\n",
      "          [-0.8771, -0.8096, -0.0929]],\n",
      "\n",
      "         [[ 1.1522,  0.5074, -0.3919],\n",
      "          [-0.7024,  1.3359,  0.7152],\n",
      "          [-0.3411, -0.1181,  0.8319]],\n",
      "\n",
      "         [[ 1.9686,  0.2805,  1.9455],\n",
      "          [ 0.6684,  0.7136, -1.9037],\n",
      "          [ 0.8977,  1.4853, -2.0146]]]])\n"
     ]
    }
   ],
   "source": [
    "# NLP Example\n",
    "batch, sentence_length, embedding_dim = 3, 3, 3\n",
    "embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
    "layer_norm = nn.LayerNorm(embedding_dim)\n",
    "# Activate module\n",
    "layer_norm(embedding)\n",
    "# Image Example\n",
    "N, C, H, W = 3, 3, 3, 3\n",
    "input = torch.randn(N, C, H, W)\n",
    "# Normalize over the last three dimensions (i.e. the channel and spatial dimensions)\n",
    "# as shown in the image below\n",
    "print(input)\n",
    "layer_norm = nn.LayerNorm([C, H, W])\n",
    "output = layer_norm(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.4008, -1.0543, -1.7911],\n",
      "          [ 1.3586,  0.4631,  1.2395],\n",
      "          [ 0.5474, -0.4621,  0.1772]],\n",
      "\n",
      "         [[ 0.4189,  0.1138,  0.9976],\n",
      "          [ 0.2338,  0.7382,  2.7651],\n",
      "          [-0.8563, -1.1009, -0.3108]],\n",
      "\n",
      "         [[-0.2624,  0.4267, -0.8547],\n",
      "          [-0.2578,  0.1593, -1.9128],\n",
      "          [-0.6617, -1.1533,  0.6382]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0517,  0.6436, -1.4734],\n",
      "          [-1.0835,  1.2238,  0.5551],\n",
      "          [ 0.6457, -0.7085,  0.0116]],\n",
      "\n",
      "         [[-0.7807, -0.2075, -0.1221],\n",
      "          [ 2.9526,  0.0226,  0.1376],\n",
      "          [ 0.5597, -0.0689, -1.0933]],\n",
      "\n",
      "         [[ 0.3146,  0.5181, -0.1209],\n",
      "          [-2.2188,  0.1540, -0.4976],\n",
      "          [ 0.5409,  0.5623, -1.5187]]],\n",
      "\n",
      "\n",
      "        [[[-0.4806, -1.0278,  1.9016],\n",
      "          [ 1.1349, -0.2936, -1.1697],\n",
      "          [-0.9976, -0.9380, -0.3057]],\n",
      "\n",
      "         [[ 0.7929,  0.2240, -0.5695],\n",
      "          [-0.8434,  0.9549,  0.4074],\n",
      "          [-0.5247, -0.3279,  0.5103]],\n",
      "\n",
      "         [[ 1.5133,  0.0238,  1.4928],\n",
      "          [ 0.3660,  0.4059, -1.9034],\n",
      "          [ 0.5684,  1.0868, -2.0013]]]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
